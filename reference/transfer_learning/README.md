# Transfer Learning

+ **A Bayesian Approach to Unsupervised One-Shot Learning of Object Categories**
> 采用基于贝叶斯分类器的算法，将已学习种类的信息通过先验概率密度函数的参数表示，新种类的训练样本更新模型参数，能够在单样本以及更多样本的情况下获得较高的分类准确率，但无法适用于零样本学习，且新种类可与原种类无关。

+ **A Survey on Transfer Learning**
> 首先定义了域和任务，域包含特征空间和样本在特征空间的概率分布，任务包含标签空间和预测函数，根据域和任务的不同可将迁移学习分为inductive transfer learning、transductive transfer learning和unsupervised learning三种，其中inductive transfer learning指源任务和目标任务不同而不论源域和目标域是否相同，transductive transfer learning指源任务和目标任务相同而源域和目标域不同，而unsupervised transfer learning和inductive transfer learning处理情况相同，但多处理无监督学习任务。根据迁移的内容可以将迁移学习分为四种，分别是基于样本的迁移、基于特征表示的迁移、基于模型参数的迁移和基于相关关系的迁移，基于样本的迁移是对源域的样本加上不同的权重使得它们能够对目标域起到帮助，基于特征表示的迁移是通过找到一种特征表示方法能够降低源域和目标域之间的差异性，基于模型参数的迁移是认为源域模型和目标域模型之间的参数有一定的相关性，基于相关关系的迁移是将源域中样本之间的相关关系迁移到目标域中。如何避免不利迁移以及如何度量可迁移性是未来研究的方向。

+ **Boosting for Transfer Learning**
> 设计了一种改进的Adaboost算法，能够将分布不同的样本中的知识进行迁移，当分布不同的样本预测错误时减小其权重，当分布相同的样本预测错误时增大其权重，从而使得分布不同中有利于分类的样本被赋予更大的权重，通过多次权重更新即可得到最终的分类器，实验表明在分布相同的样本比重较少时迁移学习相比于传统的监督学习有更明显的优越性，且在分布差异越大时误差提升的效果更加明显。

+ **Domain Adaptation via Transfer Component Analysis**
> 利用降维的思想将原始的特征空间映射到由迁移成分构成的特征空间，以减小源域和目标域的分布差异，同时为了获取标签的依赖性可采用半监督迁移成分分析方法，未来可以考虑从多个源域进行迁移成分的提取。

+ **From N to N+1: Multiclass Transfer Incremental Learning**
> 在源域上保证原有分类准确率的基础上迁移到目标域，采用最小二乘支持向量机，留一法作为误差，N+1类新模型和N类原模型的线性组合尽可能接近，N类原模型尽可能保持不变，基于以上两点建立正则化目标函数。

+ **Learning Transferable Features with Deep Adaptation Networks**
> 基于卷积神经网络的模型，由于浅层特征具有普遍性，而深层特征具有特殊性，因此深层特征的可迁移性不如浅层特征，将已训练好的网络中前几层的参数固定，中间几层的参数微调，而后几层在参数调整时需要加入该层特征和原网络该层特征之间距离的惩罚项，且采用多核算法，相比于只对单层计算距离和单核算法有较为明显的优势。

+ **One-Shot Learning of Object Categories**
> 和上一篇文章的方法相同，在更大的数据集上进行了实验，先验种类增加能够降低错误率，在目标检测和分类上均能取得较好的结果，且当新的种类和先验的种类更加相似时能取得更好的效果。

+ **Partial Transfer Learning with Selective Adversarial Networks**
> 问题背景为部分迁移，即目标域种类为源域种类中的一部分，由于源域中非目标域种类会造成负迁移，因此采用选择性对抗网络将会造成负迁移的种类排除同时在源域和目标域的共有标签空间中最小化分布差异。

+ **Safety in Numbers: Learning Categories from Few Examples with Multi Model Knowledge Transfer**
> 基于LSSVM，新模型为多个原模型的线性组合，表现优于从单个模型迁移和简单平均多个模型，当先验知识增加即原模型个数增加时，单样本学习精度逐渐提升。

+ **Transfer Learning for Visual Categorization: A Survey**
> 采用迁移学习的前提是目标域和源域的特征空间或样本分布不同，且只有少量的目标域标签样本，常用于图像分类或动作识别等机器视觉领域。主要分为特征表示层面和分类器层面两种迁移方式，特征表示层面通过特征建立源域和目标域的联系，主要分为交叉域和交叉视角两种；分类器层面通过源域学习得到的模型参数进而生成目标域的模型，主要有基于SVM，迁移AdaBoost，生成模型，模糊模型等方法。当有多个源域时，基于SVM的方法通过多个源域模型的线性组合获得目标域模型，还有基于Boosting和多核等方法。采用迁移学习可以在少量目标域样本时获得较好的表现，当样本增加时获得较快的表现提升，最终获得最好的分类效果。

+ **基于AlexNet的迁移学习在流程工业图像识别中的应用**
> 由于深度网络低层提取的特征具有一般性，基于深度网络的迁移学习一般将训练好的网络的前几层作为目标网络的前几层，其余层的参数随机初始化，前几层的参数在训练过程中可以冻结或不冻结（微调）。

+ **基于迁移学习的卷积神经网络SAR图像目标识别**
> 将3分类问题通过迁移网络的参数应用于10分类问题，为了减少网络参数，将最后的全连接层用卷积层代替，但预训练模型如果和测试模型过于接近可能会造成过拟合使得精度下降。

+ **迁移度量学习行人再识别算法**
> 行人识别算法主要分为特征描述和度量模型构建，度量模型（XQDA，交叉二次判别分析）的构建首先将特征向量投影到子空间，使得正样本对总体散度尽量小，负样本对总体散度尽量大，再在子空间中计算马氏距离作为最终的距离度量方式。在迁移到目标域的过程中，加入概率分布相似性作为约束使得源域和目标域在子空间中的概率分布尽可能接近。

+ **迁移学习研究和算法综述**
> 迁移学习主要可以解决小数据和个性化的问题，在机器视觉和自然语言处理等方面有较多的应用，除了完全迁移，也可只迁移部分相关的源域数据。